# Deep Research CLI

A comprehensive, production-ready deep research tool that performs advanced web research using DuckDuckGo search and recursive web crawling with a beautiful command-line interface.

## ğŸ” What It Does

This system takes a research query and performs deep, multi-level web research:

1. **Initial Search**: Searches DuckDuckGo for relevant results
2. **Level 1 Crawling**: Scrapes content from initial search results  
3. **Level 2 Recursive Crawling**: Follows links from initial pages and crawls them recursively
4. **Content Analysis**: Analyzes all content for relevance to your research query
5. **Report Generation**: Creates comprehensive reports in JSON and PDF formats
6. **Rich CLI Output**: Beautiful terminal output with progress indicators and formatted results

## âœ¨ Features

- ğŸ” **DuckDuckGo Integration**: Searches without API keys or rate limits
- ğŸ•·ï¸ **Recursive Web Crawling**: Follows links for deeper research
- ğŸ§  **Intelligent Content Analysis**: Scores content relevance automatically
- ğŸ“„ **PDF Report Generation**: Creates professional research reports
- ğŸ’» **Rich CLI Interface**: Beautiful terminal output with colors and formatting
- ğŸ“¦ **Importable Package**: Use programmatically in your own Python projects
- âš¡ **Fast & Respectful**: Built-in delays and proper web scraping etiquette

## ğŸš€ Installation

### From Source

```bash
# Clone the repository
git clone https://github.com/yourusername/deep-research.git
cd deep-research

# Install in development mode
pip install -e .

# Or install directly
pip install .
```

### Using pip (when published)

```bash
pip install deep-research
```

## ğŸ¯ Quick Start

### Command Line Usage

```bash
# Basic research
deep-research "How to transition from software engineering to PhD?"

# Generate PDF report
deep-research "machine learning trends 2024" --pdf

# Save results as JSON
deep-research "climate change solutions" --json

# Full example with all options
deep-research "startup funding strategies" \
    --max-results 30 \
    --max-level2 15 \
    --output-dir ./reports \
    --pdf \
    --json \
    --verbose

# Use short alias
dr "AI ethics in healthcare" --pdf
```

### Programmatic Usage

```python
# Basic usage
from deep_research import DeepResearcher

researcher = DeepResearcher()
result = researcher.research("your research query")

print(f"Found {result.total_pages_crawled} pages")
print(f"Key findings: {len(result.key_findings)}")

# Quick research with PDF
from deep_research import quick_research

result, pdf_path = quick_research("AI trends 2024")
print(f"Report saved to: {pdf_path}")

# Convenience function
import deep_research

result = deep_research.research("machine learning", max_results=10)
```

## ğŸ“– CLI Options

```
positional arguments:
  query                 Research query to investigate

optional arguments:
  --max-results N       Maximum initial search results (default: 20)
  --max-level2 N        Maximum level 2 links per page (default: 10)
  --output-dir DIR      Output directory for reports (default: research_output)
  --pdf                 Generate PDF report
  --json                Save results as JSON file
  --max-sources N       Maximum sources to display (default: 10)
  --verbose             Enable verbose logging
  --version             Show version information
  --help                Show help message
```

## ğŸ¨ Example Output

When you run a research query, you'll see beautiful formatted output:

```
ğŸ” Deep Research CLI
Advanced web crawling and research with recursive link following

ğŸ› ï¸ Research Configuration
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Setting             â”‚ Value                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Query               â”‚ machine learning trends             â”‚
â”‚ Max Initial Results â”‚ 20                                  â”‚
â”‚ Max Level 2 per Pageâ”‚ 10                                  â”‚
â”‚ Output Directory    â”‚ research_output                     â”‚
â”‚ Generate PDF        â”‚ Yes                                 â”‚
â”‚ Save JSON           â”‚ No                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸš€ Starting deep research...

ğŸ” Searching DuckDuckGo... â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
ğŸ•·ï¸ Crawling Level 1 pages... â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
ğŸ”— Extracting links... â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
ğŸ“„ Crawling Level 2 pages... â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%
ğŸ“Š Analyzing content... â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%

âœ… Research completed!

ğŸ“Š Research Summary
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric              â”‚ Value  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Query               â”‚ ml...  â”‚
â”‚ Total Pages Crawled â”‚ 45     â”‚
â”‚ Total Links Found   â”‚ 234    â”‚
â”‚ Research Time       â”‚ 23.4s  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
deep-research/
â”œâ”€â”€ deep_research/           # Main package
â”‚   â”œâ”€â”€ __init__.py         # Package initialization
â”‚   â””â”€â”€ deep_researcher.py  # Core research functionality
â”œâ”€â”€ cli.py                  # Command-line interface
â”œâ”€â”€ setup.py               # Package setup (legacy)
â”œâ”€â”€ pyproject.toml         # Modern package configuration
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ LICENSE              # MIT License
â”œâ”€â”€ CHANGELOG.md        # Version history
â”œâ”€â”€ MANIFEST.in         # Package manifest
â””â”€â”€ example_usage.py    # Usage examples
```

## ğŸ”§ Development

### Setting up for Development

```bash
# Clone the repository
git clone https://github.com/yourusername/deep-research.git
cd deep-research

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode with all extras
pip install -e .[dev,full]

# Run tests
pytest

# Format code
black .

# Check types
mypy deep_research/
```

### Building and Distribution

```bash
# Build the package
python -m build

# Upload to PyPI (maintainers only)
twine upload dist/*
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Add tests for your changes
5. Run the test suite (`pytest`)
6. Format your code (`black .`)
7. Commit your changes (`git commit -m 'Add amazing feature'`)
8. Push to the branch (`git push origin feature/amazing-feature`)
9. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [DuckDuckGo](https://duckduckgo.com/) for providing search capabilities
- [Rich](https://github.com/Textualize/rich) for beautiful terminal output
- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) for HTML parsing
- [ReportLab](https://www.reportlab.com/) for PDF generation

## ğŸ“§ Support

- ğŸ› [Report bugs](https://github.com/yourusername/deep-research/issues)
- ğŸ’¡ [Request features](https://github.com/yourusername/deep-research/issues)
- ğŸ“– [View documentation](https://github.com/yourusername/deep-research#readme)
- ğŸ’¬ [Discussions](https://github.com/yourusername/deep-research/discussions)

---

**Deep Research CLI** - Turn any research question into comprehensive insights with just one command! ğŸš€