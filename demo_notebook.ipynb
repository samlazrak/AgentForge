# Final cleanup
print("ğŸ§¹ Cleaning up...")

# Stop agents
research_agent.stop()
webscraper_agent.stop()

print("âœ… Demo completed successfully!")
print(f"ğŸ“… Demo ended at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("\nğŸ‰ Thank you for using Agent Creator!")## ğŸ¯ Conclusion

This demonstration showcased the powerful capabilities of the Agent Creator framework:

### âœ… What We Accomplished

1. **ğŸ”¬ Research Agent**: Performed comprehensive AI-powered research with automatic citation generation
2. **ğŸ•·ï¸ Webscraper Agent**: Extracted content from web sources with intelligent parsing
3. **ğŸ¤ Agent Integration**: Demonstrated seamless collaboration between agents
4. **ğŸ“ File Generation**: Created PDF reports and Jupyter notebooks automatically

### ğŸš€ Key Features Demonstrated

- **MLX Integration**: Advanced language model processing
- **Fallback Systems**: Graceful handling of missing dependencies
- **Task Management**: Built-in task tracking and status monitoring
- **Error Handling**: Robust error handling and recovery

---

**Thank you for exploring the Agent Creator framework!** ğŸ‰# Single URL scraping demonstration
demo_url = "https://news.ycombinator.com"
print(f"ğŸ•·ï¸ Scraping: {demo_url}")

scraping_result = webscraper_agent.scrape_url(demo_url)

if scraping_result.success:
    print("âœ… Scraping successful!")
    print(f"ğŸ“„ Title: {scraping_result.title}")
    print(f"ğŸ“ Content length: {len(scraping_result.text)} characters")
    print(f"ğŸ”— Links found: {len(scraping_result.links)}")
    print(f"ğŸ–¼ï¸ Images found: {len(scraping_result.images)}")
    print(f"â±ï¸ Response time: {scraping_result.response_time:.2f} seconds")
else:
    print(f"âŒ Scraping failed: {scraping_result.error}")## ğŸ•·ï¸ Webscraper Agent Demonstration

Now let's explore the capabilities of our Webscraper Agent.# Display research summary
print("ğŸ“‹ RESEARCH SUMMARY")
print("=" * 50)
print(research_result['research_result'].summary)
print("=" * 50)### ğŸ“‹ Research Summary# Define research query
research_query = "Recent developments in artificial intelligence and machine learning 2024"

print(f"ğŸ” Starting research on: {research_query}")
print("This may take a few moments...")

# Execute research
research_result = research_agent.research_topic(
    query=research_query,
    max_results=8,
    generate_pdf=True,
    generate_notebook=True
)

print("âœ… Research completed!")
print(f"ğŸ“„ Summary length: {len(research_result['research_result'].summary)} characters")
print(f"ğŸ“š Sources found: {len(research_result['research_result'].sources)}")
print(f"ğŸ“ Citations generated: {len(research_result['research_result'].citations)}")
print(f"ğŸ“ Files generated: {len(research_result['files_generated'])}")## ğŸ”¬ Research Agent Demonstration

Let's see the Research Agent in action with a comprehensive research task.# Configure the Research Agent
research_config = AgentConfig(
    name="DemoResearchAgent",
    description="AI-powered research agent for comprehensive analysis",
    capabilities=[
        "web_search", "content_analysis", "citation_generation",
        "pdf_generation", "notebook_generation"
    ]
)

# Configure the Webscraper Agent
webscraper_config = AgentConfig(
    name="DemoWebscraperAgent",
    description="Advanced web scraping agent for content extraction",
    capabilities=[
        "url_scraping", "content_extraction", "link_extraction",
        "image_extraction", "metadata_extraction", "batch_scraping"
    ]
)

# Scraping configuration
scraping_config = ScrapingConfig(
    timeout=30,
    delay_between_requests=1.0,
    max_content_length=1000000  # 1MB limit
)

# Initialize agents
research_agent = ResearchAgent(research_config)
webscraper_agent = WebscraperAgent(webscraper_config, scraping_config)

# Connect agents for enhanced functionality
research_agent.set_webscraper_agent(webscraper_agent)

# Start agents
research_agent.start()
webscraper_agent.start()

print("ğŸ¤– Agents initialized and started successfully!")
print(f"ğŸ”¬ Research Agent: {research_agent.config.name}")
print(f"ğŸ•·ï¸ Webscraper Agent: {webscraper_agent.config.name}")## ğŸ› ï¸ Agent Initialization

Let's create and configure our AI agents with proper settings.# Import required libraries
import os
import sys
from datetime import datetime
import pandas as pd
import matplotlib.pyplot as plt
import json

# Import our agent framework
from agent_creator import ResearchAgent, WebscraperAgent, LLMInterface
from agent_creator.core.base_agent import AgentConfig
from agent_creator.agents.webscraper_agent import ScrapingConfig

print("âœ… Agent Creator framework imported successfully!")
print(f"ğŸ“… Demo started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")## ğŸ“¦ Setup and Installation

First, let's import the necessary libraries and initialize our agents.# ğŸ¤– Agent Creator - Demonstration Notebook

Welcome to the Agent Creator demonstration! This notebook showcases the powerful AI-driven research and web scraping capabilities of our agent framework.

## ğŸš€ Features

- **Research Agent**: AI-powered research with MLX integration
- **Webscraper Agent**: Advanced web content extraction
- **Automated Report Generation**: PDF and Jupyter notebook outputs
- **Citation Management**: Proper academic citations
- **Agent Integration**: Seamless collaboration between agents